# OCRBase

> Self-hosted OCR SaaS with open-weight vLLM models

## What it does

- Parse: PDF/Image → Markdown
- Extract: PDF/Image → JSON (optional schema)
- Schema Gen: LLM suggests JSON schema from sample

## Tech

Backend: Elysia, Bun, PostgreSQL, Drizzle, BullMQ, Redis, MinIO
Frontend: TanStack Start, Eden Treaty, shadcn/ui
Auth: Better Auth (GitHub, email/password, organizations)
OCR: PaddleOCR-VL via @ocrbase/paddleocr-vl-ts SDK
LLM: Vercel AI SDK (@ai-sdk/openai) → OpenRouter or local vLLM

## Monorepo structure

apps/server - Elysia API server
apps/web - TanStack Start frontend
packages/db - Drizzle schema (PostgreSQL)
packages/env - t3-env validation
packages/auth - Better Auth config
packages/paddleocr-vl-ts - PaddleOCR TypeScript SDK

## SDK usage

```ts
import { PaddleOCRClient } from "@ocrbase/paddleocr-vl-ts";
const client = new PaddleOCRClient({ layoutUrl: "http://localhost:8080" });
const result = await client.parseDocument(base64, { fileType: 0 });
const md = PaddleOCRClient.combineMarkdown(result);
```

## Key patterns

- Prefixed IDs: job_xxx, sch_xxx, org_xxx
- Type-safe: Drizzle → Elysia → Eden end-to-end
- Zod validation everywhere
- BullMQ for async job processing
- WebSocket for real-time job updates

## Commands

bun run dev - Start all apps
bun run dev:server - Server only
bun run dev:web - Web only
bun run db:push - Push schema to DB
bun run db:studio - Open Drizzle Studio

## Scale target

20k+ docs/day, 200MB max file size, RTX 3060 baseline GPU
